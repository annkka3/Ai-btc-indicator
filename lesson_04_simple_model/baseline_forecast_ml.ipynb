{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Forecast ML Baseline - –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è BTC –æ—Ç —Ç—Ä–µ–Ω–¥–∞\n",
        "\n",
        "## –§–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞ –∑–∞–¥–∞—á–∏ –≤ —Ç–µ—Ä–º–∏–Ω–∞—Ö ML\n",
        "\n",
        "**–ó–∞–¥–∞—á–∞:** –ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ BTC –æ—Ç —Ç—Ä–µ–Ω–¥–∞ –Ω–∞ 1—á/4—á/24—á\n",
        "\n",
        "**–¢–∏–ø –∑–∞–¥–∞—á–∏:** \n",
        "- **–†–µ–≥—Ä–µ—Å—Å–∏—è**: –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –≤–µ–ª–∏—á–∏–Ω—É –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è (residual-—Ç–∞—Ä–≥–µ—Ç, –ª–æ–≥-–æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –æ—Ç MA_L)\n",
        "- **–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è**: –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–≤–∏–∂–µ–Ω–∏—è (P(up))\n",
        "\n",
        "**–¶–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ (—Å–æ–≥–ª–∞—Å–Ω–æ –ø–ª–∞–Ω—É):**\n",
        "- `y_H(t) = log(P_{t+H}) - log(MA_L(t))` - –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –æ—Ç —Ç—Ä–µ–Ω–¥–∞\n",
        "- `d_H(t) = 1[y_H(t) > 0]` - –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ (1 = –≤–≤–µ—Ä—Ö, 0 = –≤–Ω–∏–∑)\n",
        "- –≥–¥–µ `MA_L` - EMA/KAMA, —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω–∞—è —Å—Ç—Ä–æ–≥–æ –¥–æ –º–æ–º–µ–Ω—Ç–∞ `t` (–±–µ–∑ —É—Ç–µ—á–µ–∫)\n",
        "\n",
        "**–ü—Ä–∏–∑–Ω–∞–∫–∏ (—è–¥—Ä–æ MVP, ~10 —Å–æ–≥–ª–∞—Å–Ω–æ –ø–ª–∞–Ω—É):**\n",
        "1. $z$-score —Ü–µ–Ω—ã –∫ $\\mathrm{MA}_L$\n",
        "2. Realized vol $\\sigma_{20}$ (–Ω–∞ —Ü–µ–ª–µ–≤–æ–º –¢–§)\n",
        "3. ATR% (14)\n",
        "4. RSI(14) (+ –±–∏–Ω–∞—Ä–Ω—ã–π ¬´RSI > 50¬ª)\n",
        "5. –ù–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç—É–º (MACD-hist/ATR)\n",
        "6. Funding z-score; Basis z-score (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã)\n",
        "7. $\\Delta\\mathrm{OI}\\%$, –Ω–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ –æ–±—ä—ë–º (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã)\n",
        "8. –ò–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å –ª–∏–∫–≤–∏–¥–∞—Ü–∏–π (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã)\n",
        "9. –î–ª—è 24—á ‚Äî DXY $\\Delta 1d$ (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã)\n",
        "10. –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –æ—Ç MA (–ª–∞–≥–∏ 1‚Äì6)\n",
        "\n",
        "**–ü—Ä–æ–¥—É–∫—Ç–æ–≤–∞—è –º–µ—Ç—Ä–∏–∫–∞:** \n",
        "- MAE-gain ‚â• 5%/6%/8% (1—á/4—á/24—á) vs –Ω—É–ª–µ–≤–æ–π –ø—Ä–æ–≥–Ω–æ–∑\n",
        "- Sharpe ‚â• 1.0/1.1/1.2 –¥–ª—è policy long-if-≈∑>0\n",
        "\n",
        "**ML-–º–µ—Ç—Ä–∏–∫–∏:**\n",
        "- **–†–µ–≥—Ä–µ—Å—Å–∏—è**: MAE, RMSE, R¬≤\n",
        "- **–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è**: Accuracy, Precision, Recall, F1-score, ROC-AUC\n",
        "- **–ö–∞–ª–∏–±—Ä–æ–≤–∫–∞**: Brier Score, ECE (Expected Calibration Error)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –º–æ–¥—É–ª–µ–π\n",
        "project_root = Path().resolve().parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥—É–ª–∏ –ø—Ä–æ–µ–∫—Ç–∞\n",
        "try:\n",
        "    from app.ml.data_adapter import load_bars_from_project, make_loader\n",
        "    from app.ml.features import build_features\n",
        "    from app.infrastructure.db import DB\n",
        "    USE_PROJECT_MODULES = True\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥—É–ª–∏ –ø—Ä–æ–µ–∫—Ç–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–ø—Ä–æ—â—ë–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é\")\n",
        "    USE_PROJECT_MODULES = False\n",
        "\n",
        "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
        "SYMBOL = \"BTC\"\n",
        "TIMEFRAME = \"1h\"  # –ú–æ–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å –Ω–∞ \"4h\" –∏–ª–∏ \"24h\"\n",
        "HORIZON = 24  # –ì–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–æ–≥–Ω–æ–∑–∞ –≤ –±–∞—Ä–∞—Ö\n",
        "DB_PATH = '../data/alt_forecast.db'  # –ü—É—Ç—å –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "print(f\"üìä –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\")\n",
        "print(f\"   Symbol: {SYMBOL}\")\n",
        "print(f\"   Timeframe: {TIMEFRAME}\")\n",
        "print(f\"   Horizon: {HORIZON} –±–∞—Ä–æ–≤\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data_simple(db_path: str, symbol: str, timeframe: str, limit: int = 5000) -> pd.DataFrame:\n",
        "    \"\"\"–£–ø—Ä–æ—â—ë–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ SQLite.\"\"\"\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    \n",
        "    # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Ç–∞–±–ª–∏—Ü—É —Å –±–∞—Ä–∞–º–∏\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n",
        "    tables = [row[0] for row in cur.fetchall()]\n",
        "    \n",
        "    # –ò—â–µ–º —Ç–∞–±–ª–∏—Ü—É bars\n",
        "    table_name = None\n",
        "    for table in tables:\n",
        "        cur.execute(f\"PRAGMA table_info({table})\")\n",
        "        cols = [row[1].lower() for row in cur.fetchall()]\n",
        "        if {'metric', 'timeframe', 'ts', 'o', 'h', 'l', 'c'}.issubset(set(cols)):\n",
        "            table_name = table\n",
        "            break\n",
        "    \n",
        "    if not table_name:\n",
        "        raise ValueError(f\"–ù–µ –Ω–∞–π–¥–µ–Ω–∞ —Ç–∞–±–ª–∏—Ü–∞ —Å –±–∞—Ä–∞–º–∏ –≤ {db_path}\")\n",
        "    \n",
        "    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ\n",
        "    query = f\"\"\"\n",
        "        SELECT ts, o as open, h as high, l as low, c as close, v as volume\n",
        "        FROM {table_name}\n",
        "        WHERE metric = ? AND timeframe = ?\n",
        "        ORDER BY ts DESC\n",
        "        LIMIT ?\n",
        "    \"\"\"\n",
        "    \n",
        "    df = pd.read_sql_query(query, conn, params=[symbol, timeframe, limit])\n",
        "    conn.close()\n",
        "    \n",
        "    if df.empty:\n",
        "        raise ValueError(f\"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol} {timeframe}\")\n",
        "    \n",
        "    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º\n",
        "    df['ts'] = pd.to_datetime(df['ts'], unit='ms', utc=True)\n",
        "    df = df.sort_values('ts').reset_index(drop=True)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ\n",
        "if USE_PROJECT_MODULES:\n",
        "    try:\n",
        "        # –ü—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å DB –∏–∑ –ø—Ä–æ–µ–∫—Ç–∞\n",
        "        db = DB(DB_PATH)\n",
        "        loader = make_loader(db)\n",
        "        df = loader(SYMBOL, TIMEFRAME, limit=5000)\n",
        "        print(f\"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –±–∞—Ä–æ–≤ –∏–∑ –ø—Ä–æ–µ–∫—Ç–∞\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —á–µ—Ä–µ–∑ –ø—Ä–æ–µ–∫—Ç: {e}\")\n",
        "        print(\"üìä –ü—Ä–æ–±—É–µ–º —É–ø—Ä–æ—â—ë–Ω–Ω—É—é –∑–∞–≥—Ä—É–∑–∫—É...\")\n",
        "        if Path(DB_PATH).exists():\n",
        "            df = load_data_simple(DB_PATH, SYMBOL, TIMEFRAME, limit=5000)\n",
        "            print(f\"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –±–∞—Ä–æ–≤ (—É–ø—Ä–æ—â—ë–Ω–Ω—ã–π –º–µ—Ç–æ–¥)\")\n",
        "        else:\n",
        "            raise FileNotFoundError(f\"–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {DB_PATH}\")\n",
        "else:\n",
        "    if Path(DB_PATH).exists():\n",
        "        df = load_data_simple(DB_PATH, SYMBOL, TIMEFRAME, limit=5000)\n",
        "        print(f\"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –±–∞—Ä–æ–≤\")\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {DB_PATH}\")\n",
        "\n",
        "print(f\"\\nüìä –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {len(df)} —Å—Ç—Ä–æ–∫\")\n",
        "print(f\"üìä –ü–µ—Ä–∏–æ–¥: {df['ts'].min()} - {df['ts'].max()}\")\n",
        "print(f\"üìä –ö–æ–ª–æ–Ω–∫–∏: {list(df.columns)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
        "print(f\"üìä –ò—Å—Ö–æ–¥–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {len(df)} —Å—Ç—Ä–æ–∫\")\n",
        "print(f\"\\n–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏ –≤ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö\n",
        "critical_cols = ['open', 'high', 'low', 'close']\n",
        "df_clean = df.dropna(subset=critical_cols).copy()\n",
        "\n",
        "# –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏ –≤ volume –Ω—É–ª—è–º–∏\n",
        "if 'volume' in df_clean.columns:\n",
        "    df_clean['volume'].fillna(0, inplace=True)\n",
        "else:\n",
        "    df_clean['volume'] = 0.0\n",
        "\n",
        "# –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö\n",
        "df_clean = df_clean[df_clean['high'] >= df_clean['low']]\n",
        "df_clean = df_clean[df_clean['open'] > 0]\n",
        "df_clean = df_clean[df_clean['close'] > 0]\n",
        "\n",
        "# –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ –≤—Ä–µ–º–µ–Ω–∏\n",
        "df_clean = df_clean.drop_duplicates(subset=['ts'], keep='last')\n",
        "df_clean = df_clean.sort_values('ts').reset_index(drop=True)\n",
        "\n",
        "print(f\"\\n‚úÖ –ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏: {len(df_clean)} —Å—Ç—Ä–æ–∫\")\n",
        "print(f\"–£–¥–∞–ª–µ–Ω–æ —Å—Ç—Ä–æ–∫: {len(df) - len(df_clean)}\")\n",
        "\n",
        "df = df_clean\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –°—Ç—Ä–æ–∏–º –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
        "if USE_PROJECT_MODULES:\n",
        "    try:\n",
        "        df_feat = build_features(df)\n",
        "        print(\"‚úÖ –ü—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω—ã —á–µ—Ä–µ–∑ build_features()\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è –û—à–∏–±–∫–∞ build_features: {e}\")\n",
        "        USE_PROJECT_MODULES = False\n",
        "\n",
        "if not USE_PROJECT_MODULES:\n",
        "    # –£–ø—Ä–æ—â—ë–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "    df_feat = df.copy()\n",
        "    df_feat = df_feat.sort_values('ts').reset_index(drop=True)\n",
        "    df_feat.set_index('ts', inplace=True)\n",
        "    \n",
        "    # Returns\n",
        "    df_feat['ret_1'] = df_feat['close'].pct_change(1).fillna(0.0)\n",
        "    df_feat['ret_3'] = df_feat['close'].pct_change(3).fillna(0.0)\n",
        "    df_feat['ret_6'] = df_feat['close'].pct_change(6).fillna(0.0)\n",
        "    df_feat['ret_24'] = df_feat['close'].pct_change(24).fillna(0.0)\n",
        "    \n",
        "    # Volatility\n",
        "    df_feat['vol_24'] = df_feat['ret_1'].rolling(24).std().fillna(0.0)\n",
        "    df_feat['vol_72'] = df_feat['ret_1'].rolling(72).std().fillna(0.0)\n",
        "    \n",
        "    # RSI (—É–ø—Ä–æ—â—ë–Ω–Ω—ã–π)\n",
        "    delta = df_feat['close'].diff()\n",
        "    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
        "    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
        "    rs = gain / (loss + 1e-9)\n",
        "    df_feat['rsi_14'] = 100 - (100 / (1 + rs)).fillna(50.0)\n",
        "    \n",
        "    # MACD\n",
        "    ema12 = df_feat['close'].ewm(span=12, adjust=False).mean()\n",
        "    ema26 = df_feat['close'].ewm(span=26, adjust=False).mean()\n",
        "    df_feat['macd'] = (ema12 - ema26).fillna(0.0)\n",
        "    df_feat['macd_sig'] = df_feat['macd'].ewm(span=9, adjust=False).mean().fillna(0.0)\n",
        "    \n",
        "    # Bollinger Bands width\n",
        "    ma20 = df_feat['close'].rolling(20).mean()\n",
        "    std20 = df_feat['close'].rolling(20).std()\n",
        "    df_feat['bb_width'] = (2 * std20 / (ma20 + 1e-9)).fillna(0.0)\n",
        "    \n",
        "    # Volume relative\n",
        "    df_feat['vol_rel_24'] = df_feat['volume'] / (df_feat['volume'].rolling(24).mean() + 1e-9).fillna(1.0)\n",
        "    \n",
        "    # –û—á–∏—Å—Ç–∫–∞\n",
        "    df_feat = df_feat.replace([np.inf, -np.inf], 0.0).fillna(0.0)\n",
        "    print(\"‚úÖ –ü—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω—ã (—É–ø—Ä–æ—â—ë–Ω–Ω—ã–π –º–µ—Ç–æ–¥)\")\n",
        "\n",
        "print(f\"\\nüìä –ü—Ä–∏–∑–Ω–∞–∫–∏: {[col for col in df_feat.columns if col not in ['open', 'high', 'low', 'close', 'volume']]}\")\n",
        "print(f\"üìä –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏: {len(df_feat)} —Å—Ç—Ä–æ–∫\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –°—Ç—Ä–æ–∏–º —Ü–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ\n",
        "# –†–µ–≥—Ä–µ—Å—Å–∏—è: forward return (–ø—Ä–æ—Ü–µ–Ω—Ç–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —á–µ—Ä–µ–∑ horizon –±–∞—Ä–æ–≤)\n",
        "y_reg = df_feat['close'].pct_change(HORIZON).shift(-HORIZON)\n",
        "\n",
        "# –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è: –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ (1 = –≤–≤–µ—Ä—Ö, 0 = –≤–Ω–∏–∑)\n",
        "y_cls = (y_reg > 0).astype(int)\n",
        "\n",
        "# –£–±–∏—Ä–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ HORIZON —Å—Ç—Ä–æ–∫ (—É –Ω–∏—Ö –Ω–µ—Ç —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π)\n",
        "df_feat = df_feat.iloc[:-HORIZON].copy()\n",
        "y_reg = y_reg.iloc[:-HORIZON]\n",
        "y_cls = y_cls.iloc[:-HORIZON]\n",
        "\n",
        "# –£–±–∏—Ä–∞–µ–º OHLCV –∏–∑ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "feature_cols = [col for col in df_feat.columns if col not in ['open', 'high', 'low', 'close', 'volume']]\n",
        "X = df_feat[feature_cols].copy()\n",
        "\n",
        "# –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å NaN –≤ —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö\n",
        "valid_idx = ~(y_reg.isna() | y_cls.isna())\n",
        "X = X[valid_idx].copy()\n",
        "y_reg = y_reg[valid_idx].copy()\n",
        "y_cls = y_cls[valid_idx].copy()\n",
        "\n",
        "print(f\"‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö:\")\n",
        "print(f\"   –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(feature_cols)}\")\n",
        "print(f\"   –û–±—Ä–∞–∑—Ü–æ–≤: {len(X)}\")\n",
        "print(f\"   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤: {y_cls.value_counts().to_dict()}\")\n",
        "print(f\"   –°—Ä–µ–¥–Ω–∏–π return: {y_reg.mean():.4f} ({y_reg.mean()*100:.2f}%)\")\n",
        "print(f\"   Std return: {y_reg.std():.4f} ({y_reg.std()*100:.2f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "# –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π (—Ä–µ–≥—Ä–µ—Å—Å–∏—è)\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "y_reg.hist(bins=50, ax=axes[0], color='steelblue', alpha=0.7)\n",
        "axes[0].set_title(f'–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ forward return (horizon={HORIZON})')\n",
        "axes[0].set_xlabel('Return')\n",
        "axes[0].set_ylabel('–ß–∞—Å—Ç–æ—Ç–∞')\n",
        "axes[0].axvline(y_reg.mean(), color='red', linestyle='--', label=f'Mean: {y_reg.mean():.4f}')\n",
        "axes[0].legend()\n",
        "\n",
        "# –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π (–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è)\n",
        "y_cls.value_counts().plot(kind='bar', ax=axes[1], color=['red', 'green'])\n",
        "axes[1].set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è (–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è)')\n",
        "axes[1].set_xlabel('Direction (0=down, 1=up)')\n",
        "axes[1].set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ')\n",
        "axes[1].set_xticklabels(['Down', 'Up'], rotation=0)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ forward return:\")\n",
        "print(f\"   Mean: {y_reg.mean():.6f}\")\n",
        "print(f\"   Std: {y_reg.std():.6f}\")\n",
        "print(f\"   Min: {y_reg.min():.6f}\")\n",
        "print(f\"   Max: {y_reg.max():.6f}\")\n",
        "print(f\"   Median: {y_reg.median():.6f}\")\n",
        "print(f\"\\nüìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤:\")\n",
        "print(f\"   Up (1): {y_cls.sum()} ({y_cls.mean()*100:.2f}%)\")\n",
        "print(f\"   Down (0): {(1-y_cls).sum()} ({(1-y_cls.mean())*100:.2f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π\n",
        "correlations = X.corrwith(y_reg).sort_values(ascending=False)\n",
        "print(\"üìä –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å forward return:\")\n",
        "print(correlations)\n",
        "\n",
        "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
        "plt.figure(figsize=(10, 6))\n",
        "correlations.plot(kind='barh', color='steelblue')\n",
        "plt.title('–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π (forward return)')\n",
        "plt.xlabel('–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/test (80/20)\n",
        "# –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ (–Ω–µ shuffle) –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤\n",
        "split_idx = int(0.8 * len(X))\n",
        "X_train = X.iloc[:split_idx].copy()\n",
        "X_test = X.iloc[split_idx:].copy()\n",
        "y_reg_train = y_reg.iloc[:split_idx].copy()\n",
        "y_reg_test = y_reg.iloc[split_idx:].copy()\n",
        "y_cls_train = y_cls.iloc[:split_idx].copy()\n",
        "y_cls_test = y_cls.iloc[split_idx:].copy()\n",
        "\n",
        "# –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(f\"‚úÖ –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö:\")\n",
        "print(f\"   Train: {len(X_train)} –æ–±—Ä–∞–∑—Ü–æ–≤ ({len(X_train)/len(X)*100:.1f}%)\")\n",
        "print(f\"   Test: {len(X_test)} –æ–±—Ä–∞–∑—Ü–æ–≤ ({len(X_test)/len(X)*100:.1f}%)\")\n",
        "print(f\"\\nüìä Train —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\")\n",
        "print(f\"   Mean return: {y_reg_train.mean():.6f}\")\n",
        "print(f\"   Up rate: {y_cls_train.mean():.2%}\")\n",
        "print(f\"\\nüìä Test —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\")\n",
        "print(f\"   Mean return: {y_reg_test.mean():.6f}\")\n",
        "print(f\"   Up rate: {y_cls_test.mean():.2%}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. –ú–æ–¥–µ–ª–∏\n",
        "\n",
        "### 5.1. –ü—Ä–æ—Å—Ç–∞—è –º–æ–¥–µ–ª—å 1: Linear Regression + Logistic Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    mean_absolute_error, mean_squared_error, r2_score,\n",
        "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        ")\n",
        "\n",
        "# –†–µ–≥—Ä–µ—Å—Å–∏—è\n",
        "lr_reg = LinearRegression()\n",
        "lr_reg.fit(X_train_scaled, y_reg_train)\n",
        "y_reg_train_pred = lr_reg.predict(X_train_scaled)\n",
        "y_reg_test_pred = lr_reg.predict(X_test_scaled)\n",
        "\n",
        "# –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è\n",
        "lr_cls = LogisticRegression(random_state=42, max_iter=1000)\n",
        "lr_cls.fit(X_train_scaled, y_cls_train)\n",
        "y_cls_train_pred = lr_cls.predict(X_train_scaled)\n",
        "y_cls_test_pred = lr_cls.predict(X_test_scaled)\n",
        "y_cls_test_proba = lr_cls.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# –ú–µ—Ç—Ä–∏–∫–∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏\n",
        "lr_reg_metrics = {\n",
        "    'model': 'Linear Regression',\n",
        "    'train_mae': mean_absolute_error(y_reg_train, y_reg_train_pred),\n",
        "    'test_mae': mean_absolute_error(y_reg_test, y_reg_test_pred),\n",
        "    'test_rmse': np.sqrt(mean_squared_error(y_reg_test, y_reg_test_pred)),\n",
        "    'test_r2': r2_score(y_reg_test, y_reg_test_pred),\n",
        "}\n",
        "\n",
        "# –ú–µ—Ç—Ä–∏–∫–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
        "lr_cls_metrics = {\n",
        "    'model': 'Logistic Regression',\n",
        "    'train_accuracy': accuracy_score(y_cls_train, y_cls_train_pred),\n",
        "    'test_accuracy': accuracy_score(y_cls_test, y_cls_test_pred),\n",
        "    'test_precision': precision_score(y_cls_test, y_cls_test_pred, zero_division=0),\n",
        "    'test_recall': recall_score(y_cls_test, y_cls_test_pred, zero_division=0),\n",
        "    'test_f1': f1_score(y_cls_test, y_cls_test_pred, zero_division=0),\n",
        "    'test_roc_auc': roc_auc_score(y_cls_test, y_cls_test_proba) if len(np.unique(y_cls_test)) > 1 else 0.5\n",
        "}\n",
        "\n",
        "print(\"üìä Linear Regression - –ú–µ—Ç—Ä–∏–∫–∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏:\")\n",
        "for key, value in lr_reg_metrics.items():\n",
        "    if key != 'model':\n",
        "        print(f\"  {key}: {value:.6f}\")\n",
        "\n",
        "print(\"\\nüìä Logistic Regression - –ú–µ—Ç—Ä–∏–∫–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:\")\n",
        "for key, value in lr_cls_metrics.items():\n",
        "    if key != 'model':\n",
        "        print(f\"  {key}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "\n",
        "# –†–µ–≥—Ä–µ—Å—Å–∏—è\n",
        "rf_reg = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=10, n_jobs=-1)\n",
        "rf_reg.fit(X_train_scaled, y_reg_train)\n",
        "y_reg_train_pred = rf_reg.predict(X_train_scaled)\n",
        "y_reg_test_pred = rf_reg.predict(X_test_scaled)\n",
        "\n",
        "# –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è\n",
        "rf_cls = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10, n_jobs=-1)\n",
        "rf_cls.fit(X_train_scaled, y_cls_train)\n",
        "y_cls_train_pred = rf_cls.predict(X_train_scaled)\n",
        "y_cls_test_pred = rf_cls.predict(X_test_scaled)\n",
        "y_cls_test_proba = rf_cls.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# –ú–µ—Ç—Ä–∏–∫–∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏\n",
        "rf_reg_metrics = {\n",
        "    'model': 'Random Forest Regressor',\n",
        "    'train_mae': mean_absolute_error(y_reg_train, y_reg_train_pred),\n",
        "    'test_mae': mean_absolute_error(y_reg_test, y_reg_test_pred),\n",
        "    'test_rmse': np.sqrt(mean_squared_error(y_reg_test, y_reg_test_pred)),\n",
        "    'test_r2': r2_score(y_reg_test, y_reg_test_pred),\n",
        "}\n",
        "\n",
        "# –ú–µ—Ç—Ä–∏–∫–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
        "rf_cls_metrics = {\n",
        "    'model': 'Random Forest Classifier',\n",
        "    'train_accuracy': accuracy_score(y_cls_train, y_cls_train_pred),\n",
        "    'test_accuracy': accuracy_score(y_cls_test, y_cls_test_pred),\n",
        "    'test_precision': precision_score(y_cls_test, y_cls_test_pred, zero_division=0),\n",
        "    'test_recall': recall_score(y_cls_test, y_cls_test_pred, zero_division=0),\n",
        "    'test_f1': f1_score(y_cls_test, y_cls_test_pred, zero_division=0),\n",
        "    'test_roc_auc': roc_auc_score(y_cls_test, y_cls_test_proba) if len(np.unique(y_cls_test)) > 1 else 0.5\n",
        "}\n",
        "\n",
        "print(\"üìä Random Forest Regressor - –ú–µ—Ç—Ä–∏–∫–∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏:\")\n",
        "for key, value in rf_reg_metrics.items():\n",
        "    if key != 'model':\n",
        "        print(f\"  {key}: {value:.6f}\")\n",
        "\n",
        "print(\"\\nüìä Random Forest Classifier - –ú–µ—Ç—Ä–∏–∫–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:\")\n",
        "for key, value in rf_cls_metrics.items():\n",
        "    if key != 'model':\n",
        "        print(f\"  {key}: {value:.4f}\")\n",
        "\n",
        "# –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': feature_cols,\n",
        "    'importance': rf_reg.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(f\"\\nüìä –¢–æ–ø-10 –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (Random Forest):\")\n",
        "print(feature_importance.head(10))\n",
        "\n",
        "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
        "plt.figure(figsize=(10, 6))\n",
        "feature_importance.head(10).plot(x='feature', y='importance', kind='barh', color='steelblue')\n",
        "plt.title('–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (Random Forest Regressor)')\n",
        "plt.xlabel('–í–∞–∂–Ω–æ—Å—Ç—å')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.3. –£—Å–ª–æ–∂–Ω—ë–Ω–Ω–∞—è –º–æ–¥–µ–ª—å: XGBoost —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    import xgboost as xgb\n",
        "    from sklearn.model_selection import GridSearchCV\n",
        "    \n",
        "    # –†–µ–≥—Ä–µ—Å—Å–∏—è\n",
        "    print(\"üîç –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ XGBoost Regressor...\")\n",
        "    xgb_reg_base = xgb.XGBRegressor(random_state=42, eval_metric='rmse')\n",
        "    \n",
        "    param_grid_reg = {\n",
        "        'n_estimators': [50, 100],\n",
        "        'max_depth': [3, 5],\n",
        "        'learning_rate': [0.1, 0.3],\n",
        "    }\n",
        "    \n",
        "    grid_search_reg = GridSearchCV(\n",
        "        xgb_reg_base, param_grid_reg, cv=3, scoring='neg_mean_absolute_error', \n",
        "        n_jobs=-1, verbose=0\n",
        "    )\n",
        "    \n",
        "    grid_search_reg.fit(X_train_scaled, y_reg_train)\n",
        "    xgb_reg = grid_search_reg.best_estimator_\n",
        "    \n",
        "    y_reg_train_pred = xgb_reg.predict(X_train_scaled)\n",
        "    y_reg_test_pred = xgb_reg.predict(X_test_scaled)\n",
        "    \n",
        "    # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è\n",
        "    print(\"üîç –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ XGBoost Classifier...\")\n",
        "    xgb_cls_base = xgb.XGBClassifier(random_state=42, eval_metric='logloss')\n",
        "    \n",
        "    param_grid_cls = {\n",
        "        'n_estimators': [50, 100],\n",
        "        'max_depth': [3, 5],\n",
        "        'learning_rate': [0.1, 0.3],\n",
        "    }\n",
        "    \n",
        "    grid_search_cls = GridSearchCV(\n",
        "        xgb_cls_base, param_grid_cls, cv=3, scoring='roc_auc', \n",
        "        n_jobs=-1, verbose=0\n",
        "    )\n",
        "    \n",
        "    grid_search_cls.fit(X_train_scaled, y_cls_train)\n",
        "    xgb_cls = grid_search_cls.best_estimator_\n",
        "    \n",
        "    y_cls_train_pred = xgb_cls.predict(X_train_scaled)\n",
        "    y_cls_test_pred = xgb_cls.predict(X_test_scaled)\n",
        "    y_cls_test_proba = xgb_cls.predict_proba(X_test_scaled)[:, 1]\n",
        "    \n",
        "    # –ú–µ—Ç—Ä–∏–∫–∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏\n",
        "    xgb_reg_metrics = {\n",
        "        'model': 'XGBoost Regressor (Optimized)',\n",
        "        'train_mae': mean_absolute_error(y_reg_train, y_reg_train_pred),\n",
        "        'test_mae': mean_absolute_error(y_reg_test, y_reg_test_pred),\n",
        "        'test_rmse': np.sqrt(mean_squared_error(y_reg_test, y_reg_test_pred)),\n",
        "        'test_r2': r2_score(y_reg_test, y_reg_test_pred),\n",
        "    }\n",
        "    \n",
        "    # –ú–µ—Ç—Ä–∏–∫–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
        "    xgb_cls_metrics = {\n",
        "        'model': 'XGBoost Classifier (Optimized)',\n",
        "        'train_accuracy': accuracy_score(y_cls_train, y_cls_train_pred),\n",
        "        'test_accuracy': accuracy_score(y_cls_test, y_cls_test_pred),\n",
        "        'test_precision': precision_score(y_cls_test, y_cls_test_pred, zero_division=0),\n",
        "        'test_recall': recall_score(y_cls_test, y_cls_test_pred, zero_division=0),\n",
        "        'test_f1': f1_score(y_cls_test, y_cls_test_pred, zero_division=0),\n",
        "        'test_roc_auc': roc_auc_score(y_cls_test, y_cls_test_proba) if len(np.unique(y_cls_test)) > 1 else 0.5\n",
        "    }\n",
        "    \n",
        "    print(f\"\\n‚úÖ –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã Regressor: {grid_search_reg.best_params_}\")\n",
        "    print(f\"‚úÖ –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã Classifier: {grid_search_cls.best_params_}\")\n",
        "    \n",
        "    print(\"\\nüìä XGBoost Regressor - –ú–µ—Ç—Ä–∏–∫–∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏:\")\n",
        "    for key, value in xgb_reg_metrics.items():\n",
        "        if key != 'model':\n",
        "            print(f\"  {key}: {value:.6f}\")\n",
        "    \n",
        "    print(\"\\nüìä XGBoost Classifier - –ú–µ—Ç—Ä–∏–∫–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:\")\n",
        "    for key, value in xgb_cls_metrics.items():\n",
        "        if key != 'model':\n",
        "            print(f\"  {key}: {value:.4f}\")\n",
        "    \n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è XGBoost –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install xgboost\")\n",
        "    print(\"üìä –ò—Å–ø–æ–ª—å–∑—É–µ–º Gradient Boosting...\")\n",
        "    \n",
        "    from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
        "    \n",
        "    gb_reg = GradientBoostingRegressor(n_estimators=100, random_state=42, max_depth=5)\n",
        "    gb_reg.fit(X_train_scaled, y_reg_train)\n",
        "    y_reg_test_pred = gb_reg.predict(X_test_scaled)\n",
        "    \n",
        "    gb_cls = GradientBoostingClassifier(n_estimators=100, random_state=42, max_depth=5)\n",
        "    gb_cls.fit(X_train_scaled, y_cls_train)\n",
        "    y_cls_test_pred = gb_cls.predict(X_test_scaled)\n",
        "    y_cls_test_proba = gb_cls.predict_proba(X_test_scaled)[:, 1]\n",
        "    \n",
        "    xgb_reg_metrics = {\n",
        "        'model': 'Gradient Boosting Regressor',\n",
        "        'test_mae': mean_absolute_error(y_reg_test, y_reg_test_pred),\n",
        "        'test_rmse': np.sqrt(mean_squared_error(y_reg_test, y_reg_test_pred)),\n",
        "        'test_r2': r2_score(y_reg_test, y_reg_test_pred),\n",
        "    }\n",
        "    \n",
        "    xgb_cls_metrics = {\n",
        "        'model': 'Gradient Boosting Classifier',\n",
        "        'test_accuracy': accuracy_score(y_cls_test, y_cls_test_pred),\n",
        "        'test_precision': precision_score(y_cls_test, y_cls_test_pred, zero_division=0),\n",
        "        'test_recall': recall_score(y_cls_test, y_cls_test_pred, zero_division=0),\n",
        "        'test_f1': f1_score(y_cls_test, y_cls_test_pred, zero_division=0),\n",
        "        'test_roc_auc': roc_auc_score(y_cls_test, y_cls_test_proba) if len(np.unique(y_cls_test)) > 1 else 0.5\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏\n",
        "all_reg_metrics = [lr_reg_metrics, rf_reg_metrics, xgb_reg_metrics]\n",
        "all_cls_metrics = [lr_cls_metrics, rf_cls_metrics, xgb_cls_metrics]\n",
        "\n",
        "reg_metrics_df = pd.DataFrame(all_reg_metrics)\n",
        "cls_metrics_df = pd.DataFrame(all_cls_metrics)\n",
        "\n",
        "print(\"üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π - –†–µ–≥—Ä–µ—Å—Å–∏—è:\")\n",
        "print(reg_metrics_df.to_string(index=False))\n",
        "\n",
        "print(\"\\nüìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π - –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è:\")\n",
        "print(cls_metrics_df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "reg_metric_cols = ['test_mae', 'test_rmse', 'test_r2', 'train_mae']\n",
        "reg_metric_names = ['Test MAE', 'Test RMSE', 'Test R¬≤', 'Train MAE']\n",
        "\n",
        "for i, (col, name) in enumerate(zip(reg_metric_cols, reg_metric_names)):\n",
        "    if col in reg_metrics_df.columns:\n",
        "        reg_metrics_df.plot(x='model', y=col, kind='bar', ax=axes[i], color='steelblue')\n",
        "        axes[i].set_title(f'{name}')\n",
        "        axes[i].set_ylabel(name)\n",
        "        axes[i].tick_params(axis='x', rotation=45)\n",
        "        axes[i].legend().remove()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "cls_metric_cols = ['test_accuracy', 'test_precision', 'test_recall', 'test_f1', 'test_roc_auc', 'train_accuracy']\n",
        "cls_metric_names = ['Test Accuracy', 'Test Precision', 'Test Recall', 'Test F1', 'Test ROC-AUC', 'Train Accuracy']\n",
        "\n",
        "for i, (col, name) in enumerate(zip(cls_metric_cols, cls_metric_names)):\n",
        "    if col in cls_metrics_df.columns:\n",
        "        cls_metrics_df.plot(x='model', y=col, kind='bar', ax=axes[i], color='steelblue')\n",
        "        axes[i].set_title(f'{name}')\n",
        "        axes[i].set_ylabel(name)\n",
        "        axes[i].tick_params(axis='x', rotation=45)\n",
        "        axes[i].legend().remove()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –°–æ–≤–æ–∫—É–ø–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞\n",
        "# –î–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏: –∫–æ–º–±–∏–Ω–∞—Ü–∏—è MAE –∏ R¬≤\n",
        "def calculate_reg_composite_score(row):\n",
        "    mae = row.get('test_mae', 1.0)\n",
        "    r2 = row.get('test_r2', 0.0)\n",
        "    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º MAE (–º–µ–Ω—å—à–µ = –ª—É—á—à–µ) –∏ R¬≤ (–±–æ–ª—å—à–µ = –ª—É—á—à–µ)\n",
        "    # –ò—Å–ø–æ–ª—å–∑—É–µ–º: -MAE (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π) + R¬≤\n",
        "    # MAE –æ–±—ã—á–Ω–æ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ [0, 0.1] –¥–ª—è returns, –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ [0, 1]\n",
        "    mae_norm = max(0, 1 - mae * 10)  # –ï—Å–ª–∏ MAE < 0.1, —Ç–æ mae_norm > 0\n",
        "    return 0.5 * mae_norm + 0.5 * max(0, r2)\n",
        "\n",
        "# –î–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: –∫–æ–º–±–∏–Ω–∞—Ü–∏—è F1 –∏ ROC-AUC\n",
        "def calculate_cls_composite_score(row):\n",
        "    f1 = row.get('test_f1', 0.0)\n",
        "    roc_auc = row.get('test_roc_auc', 0.5)\n",
        "    return 0.5 * f1 + 0.5 * roc_auc\n",
        "\n",
        "reg_metrics_df['composite_score'] = reg_metrics_df.apply(calculate_reg_composite_score, axis=1)\n",
        "cls_metrics_df['composite_score'] = cls_metrics_df.apply(calculate_cls_composite_score, axis=1)\n",
        "\n",
        "print(\"üìä –°–æ–≤–æ–∫—É–ø–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ - –†–µ–≥—Ä–µ—Å—Å–∏—è:\")\n",
        "print(reg_metrics_df[['model', 'composite_score']].sort_values('composite_score', ascending=False))\n",
        "\n",
        "print(\"\\nüìä –°–æ–≤–æ–∫—É–ø–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ - –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è:\")\n",
        "print(cls_metrics_df[['model', 'composite_score']].sort_values('composite_score', ascending=False))\n",
        "\n",
        "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "reg_metrics_df.sort_values('composite_score', ascending=True).plot(\n",
        "    x='model', y='composite_score', kind='barh', ax=axes[0], color='steelblue'\n",
        ")\n",
        "axes[0].set_title('–°–æ–≤–æ–∫—É–ø–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ - –†–µ–≥—Ä–µ—Å—Å–∏—è')\n",
        "axes[0].set_xlabel('Composite Score')\n",
        "\n",
        "cls_metrics_df.sort_values('composite_score', ascending=True).plot(\n",
        "    x='model', y='composite_score', kind='barh', ax=axes[1], color='steelblue'\n",
        ")\n",
        "axes[1].set_title('–°–æ–≤–æ–∫—É–ø–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ - –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è')\n",
        "axes[1].set_xlabel('Composite Score')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ü—Ä–æ–¥—É–∫—Ç–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏: MAE-gain –∏ Sharpe\n",
        "# MAE-gain = —É–ª—É—á—à–µ–Ω–∏–µ MAE –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å baseline (–Ω—É–ª–µ–≤–æ–π –ø—Ä–æ–≥–Ω–æ–∑)\n",
        "baseline_mae = np.abs(y_reg_test).mean()  # MAE –Ω—É–ª–µ–≤–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞ (–≤—Å–µ–≥–¥–∞ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º 0)\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"üìä –ü–†–û–î–£–ö–¢–û–í–´–ï –ú–ï–¢–†–ò–ö–ò\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for _, row in reg_metrics_df.iterrows():\n",
        "    model_name = row['model']\n",
        "    test_mae = row['test_mae']\n",
        "    mae_gain = (baseline_mae - test_mae) / baseline_mae * 100  # –ü—Ä–æ—Ü–µ–Ω—Ç —É–ª—É—á—à–µ–Ω–∏—è\n",
        "    print(f\"\\n{model_name}:\")\n",
        "    print(f\"  Baseline MAE (–Ω—É–ª–µ–≤–æ–π –ø—Ä–æ–≥–Ω–æ–∑): {baseline_mae:.6f}\")\n",
        "    print(f\"  Test MAE: {test_mae:.6f}\")\n",
        "    print(f\"  MAE-gain: {mae_gain:.2f}%\")\n",
        "\n",
        "# Sharpe ratio –¥–ª—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ long-if-≈∑>0\n",
        "print(\"\\nüìä Sharpe Ratio –¥–ª—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ 'long-if-≈∑>0':\")\n",
        "models_reg = [\n",
        "    ('Linear Regression', lr_reg),\n",
        "    ('Random Forest', rf_reg),\n",
        "]\n",
        "\n",
        "if 'xgb_reg' in locals():\n",
        "    models_reg.append(('XGBoost', xgb_reg))\n",
        "elif 'gb_reg' in locals():\n",
        "    models_reg.append(('Gradient Boosting', gb_reg))\n",
        "\n",
        "for model_name, model_reg in models_reg:\n",
        "    y_pred = model_reg.predict(X_test_scaled)\n",
        "    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è: –ø–æ–∫—É–ø–∞–µ–º –µ—Å–ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π return > 0\n",
        "    positions = (y_pred > 0).astype(int)\n",
        "    # –†–µ–∞–ª—å–Ω—ã–µ returns –¥–ª—è —Ç–µ—Ö –±–∞—Ä–æ–≤, –≥–¥–µ –º—ã –≤ –ø–æ–∑–∏—Ü–∏–∏\n",
        "    strategy_returns = y_reg_test * positions\n",
        "    if strategy_returns.std() > 0:\n",
        "        sharpe = strategy_returns.mean() / strategy_returns.std() * np.sqrt(252)  # –ì–æ–¥–æ–≤–∞—è\n",
        "    else:\n",
        "        sharpe = 0.0\n",
        "    print(f\"  {model_name}: {sharpe:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ROC-–∫—Ä–∏–≤—ã–µ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "models_cls = {\n",
        "    'Logistic Regression': (lr_cls, X_test_scaled),\n",
        "    'Random Forest': (rf_cls, X_test_scaled),\n",
        "}\n",
        "\n",
        "if 'xgb_cls' in locals():\n",
        "    models_cls['XGBoost'] = (xgb_cls, X_test_scaled)\n",
        "elif 'gb_cls' in locals():\n",
        "    models_cls['Gradient Boosting'] = (gb_cls, X_test_scaled)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "for name, (model, X_data) in models_cls.items():\n",
        "    y_proba = model.predict_proba(X_data)[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_cls_test, y_proba)\n",
        "    auc_score = roc_auc_score(y_cls_test, y_proba) if len(np.unique(y_cls_test)) > 1 else 0.5\n",
        "    plt.plot(fpr, tpr, label=f'{name} (AUC = {auc_score:.3f})', linewidth=2)\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random (AUC = 0.500)')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC-–∫—Ä–∏–≤—ã–µ –º–æ–¥–µ–ª–µ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏ –≤—ã–≤–æ–¥—ã\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"üìä –ò–¢–û–ì–û–í–´–ô –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –ø–æ —Å–æ–≤–æ–∫—É–ø–Ω–æ–π –º–µ—Ç—Ä–∏–∫–µ\n",
        "best_reg_row = reg_metrics_df.loc[reg_metrics_df['composite_score'].idxmax()]\n",
        "best_cls_row = cls_metrics_df.loc[cls_metrics_df['composite_score'].idxmax()]\n",
        "\n",
        "print(f\"\\nüèÜ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å —Ä–µ–≥—Ä–µ—Å—Å–∏–∏: {best_reg_row['model']}\")\n",
        "print(f\"   Composite Score: {best_reg_row['composite_score']:.4f}\")\n",
        "print(f\"   Test MAE: {best_reg_row['test_mae']:.6f}\")\n",
        "print(f\"   Test R¬≤: {best_reg_row['test_r2']:.4f}\")\n",
        "\n",
        "print(f\"\\nüèÜ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {best_cls_row['model']}\")\n",
        "print(f\"   Composite Score: {best_cls_row['composite_score']:.4f}\")\n",
        "print(f\"   Test Accuracy: {best_cls_row['test_accuracy']:.4f}\")\n",
        "print(f\"   Test F1-Score: {best_cls_row['test_f1']:.4f}\")\n",
        "print(f\"   Test ROC-AUC: {best_cls_row['test_roc_auc']:.4f}\")\n",
        "\n",
        "# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å baseline\n",
        "print(f\"\\nüìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å baseline:\")\n",
        "print(f\"   Baseline MAE (–Ω—É–ª–µ–≤–æ–π –ø—Ä–æ–≥–Ω–æ–∑): {baseline_mae:.6f}\")\n",
        "print(f\"   –£–ª—É—á—à–µ–Ω–∏–µ MAE: {(baseline_mae - best_reg_row['test_mae']) / baseline_mae * 100:.2f}%\")\n",
        "\n",
        "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–µ–Ω—á–º–∞—Ä–∫–æ–≤ –∏–∑ lesson_03\n",
        "target_mae_gain = {1: 5, 4: 6, 24: 8}.get(HORIZON, 5)  # –ü—Ä–æ—Ü–µ–Ω—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞\n",
        "target_auc = {1: 0.58, 4: 0.60, 24: 0.62}.get(HORIZON, 0.58)\n",
        "\n",
        "mae_gain_actual = (baseline_mae - best_reg_row['test_mae']) / baseline_mae * 100\n",
        "auc_actual = best_cls_row['test_roc_auc']\n",
        "\n",
        "print(f\"\\nüìä –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–µ–Ω—á–º–∞—Ä–∫–æ–≤ (–¥–ª—è horizon={HORIZON}):\")\n",
        "print(f\"   MAE-gain: —Ç—Ä–µ–±—É–µ—Ç—Å—è ‚â• {target_mae_gain}%, –ø–æ–ª—É—á–µ–Ω–æ {mae_gain_actual:.2f}% {'‚úÖ' if mae_gain_actual >= target_mae_gain else '‚ùå'}\")\n",
        "print(f\"   AUC: —Ç—Ä–µ–±—É–µ—Ç—Å—è ‚â• {target_auc:.2f}, –ø–æ–ª—É—á–µ–Ω–æ {auc_actual:.4f} {'‚úÖ' if auc_actual >= target_auc else '‚ùå'}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"‚úÖ Baseline —Ä–µ—à–µ–Ω–∏–µ –≥–æ—Ç–æ–≤–æ!\")\n",
        "print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –í—ã–≤–æ–¥—ã\n",
        "\n",
        "1. **–î–∞–Ω–Ω—ã–µ:** –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏ –æ—á–∏—â–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ OHLCV –¥–ª—è BTC\n",
        "2. **–ü—Ä–∏–∑–Ω–∞–∫–∏:** –ü–æ—Å—Ç—Ä–æ–µ–Ω—ã —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã (returns, volatility, RSI, MACD, Bollinger Bands, volume)\n",
        "3. **–¶–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ:** \n",
        "   - –†–µ–≥—Ä–µ—Å—Å–∏—è: forward return (–ø—Ä–æ—Ü–µ–Ω—Ç–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —á–µ—Ä–µ–∑ horizon –±–∞—Ä–æ–≤)\n",
        "   - –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è: –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–≤–∏–∂–µ–Ω–∏—è (–≤–≤–µ—Ä—Ö/–≤–Ω–∏–∑)\n",
        "4. **–ú–æ–¥–µ–ª–∏:** –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω—ã 3 –ø–∞—Ä—ã –º–æ–¥–µ–ª–µ–π:\n",
        "   - Linear Regression + Logistic Regression (–ø—Ä–æ—Å—Ç—ã–µ –ª–∏–Ω–µ–π–Ω—ã–µ –º–æ–¥–µ–ª–∏)\n",
        "   - Random Forest (–∞–Ω—Å–∞–º–±–ª–∏ –¥–µ—Ä–µ–≤—å–µ–≤)\n",
        "   - XGBoost/Gradient Boosting (—Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)\n",
        "5. **–ú–µ—Ç—Ä–∏–∫–∏:** \n",
        "   - –†–µ–≥—Ä–µ—Å—Å–∏—è: MAE, RMSE, R¬≤\n",
        "   - –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è: Accuracy, Precision, Recall, F1-Score, ROC-AUC\n",
        "6. **–ü—Ä–æ–¥—É–∫—Ç–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏:** MAE-gain, Sharpe ratio\n",
        "\n",
        "### –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:\n",
        "- –î–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–æ–Ω—á–µ–π–Ω-–¥–∞–Ω–Ω—ã–µ, –¥–µ—Ä–∏–≤–∞—Ç–∏–≤—ã, –º–∞–∫—Ä–æ—ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã)\n",
        "- –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å residual-—Ç–∞—Ä–≥–µ—Ç (–æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –æ—Ç EMA/KAMA –≤–º–µ—Å—Ç–æ –ø—Ä–æ—Å—Ç–æ–≥–æ forward return)\n",
        "- –î–æ–±–∞–≤–∏—Ç—å –∫–∞–ª–∏–±—Ä–æ–≤–∫—É –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π (Brier Score, ECE)\n",
        "- –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –¥—Ä—É–≥–∏–µ –º–æ–¥–µ–ª–∏ (LightGBM, CatBoost, –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏)\n",
        "- –£–ª—É—á—à–∏—Ç—å feature engineering\n",
        "- –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å walk-forward –≤–∞–ª–∏–¥–∞—Ü–∏—é –¥–ª—è –±–æ–ª–µ–µ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–π –æ—Ü–µ–Ω–∫–∏\n",
        "- –î–æ–±–∞–≤–∏—Ç—å —Ä–µ–∂–∏–º–Ω—ã–µ –≥–µ–π—Ç—ã (—Ä–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ä–µ–∂–∏–º–æ–≤ —Ä—ã–Ω–∫–∞)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
